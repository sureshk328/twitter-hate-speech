{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9effe310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import nltk\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b90b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "stopword=set(stopwords.words('english'))\n",
    "data = pd.read_csv(\"twitter.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf7fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet                 labels  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language  \n"
     ]
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"].map({0: \"Hate Speech\", \n",
    "                                    1: \"Offensive Language\", \n",
    "                                    2: \"No Hate and Offensive\"})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737982be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet                 labels\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive\n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language\n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language\n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language\n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b2880a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(z):\n",
    "    return (z[:,None]==np.arange(z.max())).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff79d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt mayasolov woman shouldnt complain clean ho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt  boy dat coldtyga dwn bad cuffin dat hoe  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt urkindofbrand dawg rt  ever fuck bitch sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt cganderson vivabas look like tranni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt shenikarobert shit hear might true might f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>yous muthafin lie   coreyemanuel right tl tras...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>youv gone broke wrong heart babi drove redneck...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitch tellin lie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>ruffl  ntac eileen dahlia  beauti color combin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  labels\n",
       "0       rt mayasolov woman shouldnt complain clean ho...       2\n",
       "1       rt  boy dat coldtyga dwn bad cuffin dat hoe  ...       1\n",
       "2       rt urkindofbrand dawg rt  ever fuck bitch sta...       1\n",
       "3                 rt cganderson vivabas look like tranni       1\n",
       "4       rt shenikarobert shit hear might true might f...       1\n",
       "...                                                  ...     ...\n",
       "24778  yous muthafin lie   coreyemanuel right tl tras...       1\n",
       "24779  youv gone broke wrong heart babi drove redneck...       2\n",
       "24780  young buck wanna eat dat nigguh like aint fuck...       1\n",
       "24781                     youu got wild bitch tellin lie       1\n",
       "24782  ruffl  ntac eileen dahlia  beauti color combin...       2\n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"labels\"].replace({\"Hate Speech\": 0, \"Offensive Language\": 1, \"No Hate and Offensive\": 2}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ccafd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "y = np.array(data[\"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f82c3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "y = np.array(data[\"labels\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "y_train = binarize(y_train)\n",
    "y_test = binarize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf821367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train: (19826, 25693)\n",
      "Shape x_test: (4957, 25693)\n",
      "Shape y_train: (19826, 2)\n",
      "Shape y_test: (4957, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape X_train:\",x_train.shape)\n",
    "print(\"Shape x_test:\",x_test.shape)\n",
    "print(\"Shape y_train:\",y_train.shape)\n",
    "print(\"Shape y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a8c6711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19826x25693 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 158277 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb9e0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1/(1+np.exp(-z))\n",
    "\n",
    "# Derivative of sigmoid function :\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "#ReLu\n",
    "def relu(z):\n",
    "    return np.maximum(0.01*z,z)\n",
    "\n",
    "# Derivative for ReLU\n",
    "def relu_prime(z):\n",
    "    z[z<=0]=0.01\n",
    "    z[z>0]=1\n",
    "    return z\n",
    "\n",
    "def softmax(z, _axis=0):\n",
    "    stable_z=z-np.max(z)\n",
    "    e_z=np.exp(stable_z)\n",
    "    return e_z/np.sum(e_z,axis=_axis, keepdims=True)\n",
    "\n",
    "def softmax_prime(z):\n",
    "    J=-z[...,None]*z[None,...]\n",
    "    J_diag=np.einsum('ii -> i',J)\n",
    "    j_diag[:]=z*(1. -z)\n",
    "    return J.sum(axis=1)\n",
    "\n",
    "def weight_init(inp,out):\n",
    "    return np.random.randn(inp,out)/np.sqrt(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0d01eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(units_count, x, y, lr, epochs, bias=False, _seed=42):\n",
    "    batch_size, ni = x.shape[-2:]\n",
    "    print(batch_size)\n",
    "    units_count.insert(0,ni)\n",
    "    units_count_arr = np.array(units_count)\n",
    "    L, = units_count_arr.shape # Number of layers + 1\n",
    "    \n",
    "    arr_view = as_strided(units_count_arr, shape=(L-1,2), strides=(4,4))\n",
    "    print(arr_view)\n",
    "    rng = np.random.default_rng(seed=_seed)\n",
    "    wghts = [None]*(L-1)\n",
    "    intercepts = [None]*(L-1)\n",
    "    # WEIGHTS INITIALIZATION\n",
    "    for i in range(L-1):\n",
    "        w_cols, w_rows = arr_view[i,:]\n",
    "        print(\"w_cols, w_rows\",i,w_rows, w_cols)\n",
    "        wghts[i] = weight_init(w_rows, w_cols)\n",
    "        #wghts[i] = rng.random((w_rows, w_cols))\n",
    "        #print(\"Weight\",i,wghts[i].shape)\n",
    "        if bias:\n",
    "            intercepts[i] = rng.random((w_rows,))\n",
    "            #print(\"intercepts\",i,intercepts[i].shape)\n",
    "    costs = np.zeros(epochs)\n",
    "    # Gradient Descent\n",
    "    for epoch in range(epochs):\n",
    "        # FORWARD PROPAGATION\n",
    "        # hidden layer 1 implementation, relu activation\n",
    "        print(x)\n",
    "        h1a = np.einsum('hi,Bi -> Bh', wghts[0], x)\n",
    "        if bias:\n",
    "            h1a = h1a + intercepts[0]\n",
    "        h1 = relu(h1a)\n",
    "        \n",
    "        \n",
    "        # hidden layer 2 implementation, sigmoid activation\n",
    "        h2a = np.einsum('ho,Bo -> Bh', wghts[1], h1) \n",
    "        if bias:\n",
    "            h2a = h2a + intercepts[1]\n",
    "        h2 = sigmoid(h2a)\n",
    "        \n",
    "        # hidden layer 3 implementation, sigmoid activation\n",
    "        h3a = np.einsum('ho,Bo -> Bh', wghts[2], h2) \n",
    "        if bias:\n",
    "            h3a = h3a + intercepts[2]\n",
    "        h3 = sigmoid(h3a)\n",
    "        \n",
    "        # hidden layer 4 implementation, sigmoid activation\n",
    "        h4a = np.einsum('ho,Bo -> Bh', wghts[3], h3) \n",
    "        if bias:\n",
    "            h4a = h4a + intercepts[3]\n",
    "        #hyp = softmax(h4a,_axis=1)\n",
    "        hyp=sigmoid(h4a)\n",
    "        \n",
    "        \n",
    "        \n",
    "        current_epoch_cost = -np.einsum('Bi,Bi', y, np.log(hyp))/batch_size\n",
    "        \n",
    "        costs[epoch] = current_epoch_cost\n",
    "        if(epoch%20000==0):\n",
    "            print(\"Epoch:\",epoch, \" Cost:\",current_epoch_cost)\n",
    "    \n",
    "    \n",
    "        # BACKWARD PROPAGATION\n",
    "        # layer 4\n",
    "        dJ_dH4a = hyp - y\n",
    "        dJ_dW3 = np.einsum('Bi,Bj -> ij',dJ_dH4a, h3)/batch_size\n",
    "        \n",
    "        # layer 3\n",
    "        dJ_dH3 = np.einsum('Bi,ij -> Bj', dJ_dH4a, wghts[3])\n",
    "        dJ_dH3a = dJ_dH3*sigmoid_prime(h3a)\n",
    "        dJ_dW2 = np.einsum('Bi,Bj -> ij',dJ_dH3a, h2)/batch_size\n",
    "        \n",
    "        \n",
    "        # layer 2\n",
    "        dJ_dH2 = np.einsum('Bi,ij -> Bj', dJ_dH3a, wghts[2])\n",
    "        dJ_dH2a = dJ_dH2*sigmoid_prime(h2a)\n",
    "        dJ_dW1 = np.einsum('Bi,Bj -> ij',dJ_dH2a, h1)/batch_size\n",
    "        \n",
    "        \n",
    "        \n",
    "        # layer 1\n",
    "        dJ_dH1 = np.einsum('Bi,ij -> Bj', dJ_dH2a, wghts[1])\n",
    "        dJ_dH1a = dJ_dH1*relu_prime(h1a)\n",
    "        dJ_dW0 = np.einsum('Bi,Bj -> ij',dJ_dH1a, x)/batch_size\n",
    "        \n",
    "        \n",
    "        if bias:\n",
    "            dJ_dB3 = np.einsum(\"Bi -> i\", dJ_dH4a)/batch_size\n",
    "            dJ_dB2 = np.einsum(\"Bi -> i\", dJ_dH3a)/batch_size\n",
    "            dJ_dB1 = np.einsum(\"Bi -> i\", dJ_dH2a)/batch_size\n",
    "            dJ_dB0 = np.einsum(\"Bi -> i\",dJ_dH1a)/batch_size\n",
    "            \n",
    "        \n",
    "        # WEIGHTS ADJUSTMENT\n",
    "        wghts[3] = wghts[3] - lr*dJ_dW3\n",
    "        wghts[2] = wghts[2] - lr*dJ_dW2\n",
    "        wghts[1] = wghts[1] - lr*dJ_dW1\n",
    "        wghts[0] = wghts[0] - lr*dJ_dW0\n",
    "        if bias:\n",
    "            intercepts[3] = intercepts[3] - lr*dJ_dB3\n",
    "            intercepts[2] = intercepts[2] - lr*dJ_dB2\n",
    "            intercepts[1] = intercepts[1] - lr*dJ_dB1\n",
    "            intercepts[0] = intercepts[0] - lr*dJ_dB0\n",
    "    if bias:\n",
    "        return (costs, wghts, intercepts)\n",
    "    else:\n",
    "        return (costs, wghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb9d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,fw,fb):\n",
    "    h1a = np.einsum('hi,Bi -> Bh', fw[0], x)+fb[0]\n",
    "    h1 = relu(h1a)\n",
    "    h2a = np.einsum('hi,Bi-> Bh',fw[1],h1)+fb[1]\n",
    "    h2=sigmoid(h2a)\n",
    "    h3a=np.einsum('hi,Bi-> Bh',fw[2],h2)+fb[2]\n",
    "    h3=sigmoid(h3a)\n",
    "    h4a=np.einsum('ho,Bo-> Bh',fw[3],h3)+fb[3]\n",
    "    return sigmoid(h4a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9529e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19826\n",
      "[[25693    14]\n",
      " [   14    10]\n",
      " [   10    14]\n",
      " [   14     3]]\n",
      "w_cols, w_rows 0 14 25693\n",
      "w_cols, w_rows 1 10 14\n",
      "w_cols, w_rows 2 14 10\n",
      "w_cols, w_rows 3 3 14\n",
      "  (0, 18926)\t1\n",
      "  (0, 23688)\t1\n",
      "  (0, 8329)\t1\n",
      "  (0, 17042)\t1\n",
      "  (0, 17422)\t1\n",
      "  (0, 24595)\t1\n",
      "  (0, 24421)\t1\n",
      "  (0, 16721)\t1\n",
      "  (0, 7700)\t1\n",
      "  (0, 17497)\t1\n",
      "  (0, 6655)\t1\n",
      "  (0, 16592)\t1\n",
      "  (0, 9898)\t1\n",
      "  (0, 8059)\t1\n",
      "  (0, 22045)\t1\n",
      "  (1, 22343)\t1\n",
      "  (1, 19499)\t1\n",
      "  (1, 2094)\t1\n",
      "  (1, 17025)\t1\n",
      "  (1, 8045)\t1\n",
      "  (1, 24986)\t1\n",
      "  (1, 16870)\t2\n",
      "  (1, 11620)\t1\n",
      "  (1, 10793)\t1\n",
      "  (2, 18926)\t1\n",
      "  :\t:\n",
      "  (19822, 19729)\t1\n",
      "  (19822, 25396)\t1\n",
      "  (19822, 2672)\t1\n",
      "  (19822, 6614)\t1\n",
      "  (19823, 17907)\t1\n",
      "  (19823, 9188)\t1\n",
      "  (19823, 17400)\t1\n",
      "  (19823, 17352)\t1\n",
      "  (19823, 664)\t2\n",
      "  (19823, 2839)\t1\n",
      "  (19824, 18926)\t1\n",
      "  (19824, 8329)\t1\n",
      "  (19824, 7392)\t1\n",
      "  (19824, 17788)\t1\n",
      "  (19824, 4668)\t1\n",
      "  (19824, 830)\t1\n",
      "  (19824, 971)\t1\n",
      "  (19824, 16922)\t1\n",
      "  (19824, 22420)\t1\n",
      "  (19824, 11712)\t1\n",
      "  (19824, 3302)\t1\n",
      "  (19824, 1989)\t1\n",
      "  (19825, 2128)\t1\n",
      "  (19825, 19866)\t1\n",
      "  (19825, 19290)\t1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "einstein sum subscripts string contains too many subscripts for operand 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16436/3397276050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0munit_per_layer_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcosts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munit_per_layer_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16436/4206064359.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(units_count, x, y, lr, epochs, bias, _seed)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# hidden layer 1 implementation, relu activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mh1a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hi,Bi -> Bh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwghts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mh1a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh1a\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mintercepts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\core\\einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspecified_out\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     \u001b[1;31m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: einstein sum subscripts string contains too many subscripts for operand 1"
     ]
    }
   ],
   "source": [
    "unit_per_layer_counts = [14,10,14,3]\n",
    "costs, fw, fb = train_batch(unit_per_layer_counts, x_train, y_train, lr=0.01, epochs=100000, bias=True)\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcce8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
